{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34c79e8-1911-4228-bc6f-d26a228c8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset (make sure the file path is correct)\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
    "column_names = [\n",
    "    'checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status',\n",
    "    'employment', 'personal_status', 'other_parties', 'residence_since', 'property_magnitude', 'housing',\n",
    "    'existing_credits', 'job', 'num_dependents', 'own_telephone', 'foreign_worker', 'class'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(url, delimiter=' ', header=None, names=column_names)\n",
    "\n",
    "# Preprocessing the data: Encoding categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Applying label encoding to all columns that are categorical\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':  # If column is categorical\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6681d34c-35a6-4851-b466-3d055eeb74db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.87      0.80       141\n",
      "           2       0.49      0.29      0.36        59\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.62      0.58      0.58       200\n",
      "weighted avg       0.67      0.70      0.67       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[123  18]\n",
      " [ 42  17]]\n"
     ]
    }
   ],
   "source": [
    "# 2. Build the Random Forest Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e6d40e-6eac-4543-bbb1-92ad764613f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chirayu\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Accuracy Score (Tuned Model):  0.725\n",
      "Classification Report (Tuned Model):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.93      0.83       141\n",
      "           2       0.58      0.24      0.34        59\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.66      0.58      0.58       200\n",
      "weighted avg       0.70      0.72      0.68       200\n",
      "\n",
      "Confusion Matrix (Tuned Model):\n",
      " [[131  10]\n",
      " [ 45  14]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Hyperparameter Tuning Using GridSearchCV\n",
    "\n",
    "# Set the parameters for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform Grid Search to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to predict on the test set\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_tuned = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model's performance\n",
    "print(\"Accuracy Score (Tuned Model): \", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Classification Report (Tuned Model):\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion Matrix (Tuned Model):\\n\", confusion_matrix(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9fc62ca-2473-433d-88d9-1eea98a14cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking_status       0\n",
      "duration              0\n",
      "credit_history        0\n",
      "purpose               0\n",
      "credit_amount         0\n",
      "savings_status        0\n",
      "employment            0\n",
      "personal_status       0\n",
      "other_parties         0\n",
      "residence_since       0\n",
      "property_magnitude    0\n",
      "housing               0\n",
      "existing_credits      0\n",
      "job                   0\n",
      "num_dependents        0\n",
      "own_telephone         0\n",
      "foreign_worker        0\n",
      "class                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
    "\n",
    "# Column names based on the UCI dataset description\n",
    "column_names = [\n",
    "    'checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount', 'savings_status',\n",
    "    'employment', 'personal_status', 'other_parties', 'residence_since', 'property_magnitude', 'housing',\n",
    "    'existing_credits', 'job', 'num_dependents', 'own_telephone', 'foreign_worker', 'class'\n",
    "]\n",
    "\n",
    "# Load the dataset from the URL\n",
    "df = pd.read_csv(url, delimiter=' ', header=None, names=column_names)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c098c662-8f1d-4d12-b5c7-14f2d6c22f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            checking_status  duration  credit_history  purpose  credit_amount  \\\n",
      "A11 6  A34                4      1169               4        4              4   \n",
      "A12 48 A32                4      5951               0        2              2   \n",
      "A14 12 A34                7      2096               0        3              2   \n",
      "A11 42 A32                3      7882               0        3              2   \n",
      "    24 A33                0      4870               0        2              3   \n",
      "\n",
      "            savings_status  employment  personal_status  other_parties  \\\n",
      "A11 6  A34               2           0                4              0   \n",
      "A12 48 A32               1           0                2              0   \n",
      "A14 12 A34               2           0                3              0   \n",
      "A11 42 A32               2           2                4              1   \n",
      "    24 A33               2           0                4              3   \n",
      "\n",
      "            residence_since  property_magnitude  housing  existing_credits  \\\n",
      "A11 6  A34               67                   2        1                 2   \n",
      "A12 48 A32               22                   2        1                 1   \n",
      "A14 12 A34               49                   2        1                 1   \n",
      "A11 42 A32               45                   2        2                 1   \n",
      "    24 A33               53                   2        2                 2   \n",
      "\n",
      "            job  num_dependents  own_telephone  foreign_worker  class  \n",
      "A11 6  A34    2               1              1               0      1  \n",
      "A12 48 A32    2               1              0               0      2  \n",
      "A14 12 A34    1               2              0               0      1  \n",
      "A11 42 A32    2               2              0               0      1  \n",
      "    24 A33    2               2              0               0      2  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each categorical feature\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':  # If column is categorical\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Verify the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b28692c-1350-4109-b82a-d402b4700297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to the feature columns (excluding target 'class')\n",
    "X = df.drop('class', axis=1)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Now X_scaled is the scaled version of your features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f1b7f38-b60a-4e6d-966d-5f7dec8c1ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 17) (200, 17) (800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Verify the shapes of the resulting splits\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1467e68-ae2e-472a-807f-58c938efe5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Baseline Model): 0.735\n",
      "\n",
      "Classification Report (Baseline Model):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.92      0.83       140\n",
      "           2       0.62      0.30      0.40        60\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.69      0.61      0.62       200\n",
      "weighted avg       0.71      0.73      0.70       200\n",
      "\n",
      "\n",
      "Confusion Matrix (Baseline Model):\n",
      " [[129  11]\n",
      " [ 42  18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy Score (Baseline Model):\", accuracy)\n",
    "print(\"\\nClassification Report (Baseline Model):\\n\", class_report)\n",
    "print(\"\\nConfusion Matrix (Baseline Model):\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "825f4392-9ecf-472e-9d9b-b302f051e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Balanced Model): 0.73\n",
      "\n",
      "Classification Report (Balanced Model):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.89      0.82       140\n",
      "           2       0.58      0.35      0.44        60\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.67      0.62      0.63       200\n",
      "weighted avg       0.71      0.73      0.71       200\n",
      "\n",
      "\n",
      "Confusion Matrix (Balanced Model):\n",
      " [[125  15]\n",
      " [ 39  21]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model with class_weight='balanced'\n",
    "rf_balanced = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=10)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_balanced = rf_balanced.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_balanced = accuracy_score(y_test, y_pred_balanced)\n",
    "class_report_balanced = classification_report(y_test, y_pred_balanced)\n",
    "conf_matrix_balanced = confusion_matrix(y_test, y_pred_balanced)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy Score (Balanced Model):\", accuracy_balanced)\n",
    "print(\"\\nClassification Report (Balanced Model):\\n\", class_report_balanced)\n",
    "print(\"\\nConfusion Matrix (Balanced Model):\\n\", conf_matrix_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "207f1462-06fb-4fce-b64f-5a6fba2723d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Threshold Adjusted Model): 0.655\n",
      "\n",
      "Classification Report (Threshold Adjusted Model):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.69      0.74       140\n",
      "           2       0.44      0.58      0.50        60\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.62      0.63      0.62       200\n",
      "weighted avg       0.69      0.66      0.67       200\n",
      "\n",
      "\n",
      "Confusion Matrix (Threshold Adjusted Model):\n",
      " [[96 44]\n",
      " [25 35]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Get predicted probabilities for each class (class 1 and class 2)\n",
    "y_prob = rf_balanced.predict_proba(X_test)\n",
    "\n",
    "# Let's choose a threshold of 0.4 for class 2 (Bad Credit)\n",
    "threshold = 0.4\n",
    "\n",
    "# Adjust the prediction: if the probability of class 2 is greater than the threshold, predict class 2\n",
    "y_pred_threshold = np.where(y_prob[:, 1] > threshold, 2, 1)\n",
    "\n",
    "# Evaluate the model's performance with the adjusted threshold\n",
    "accuracy_threshold = accuracy_score(y_test, y_pred_threshold)\n",
    "class_report_threshold = classification_report(y_test, y_pred_threshold)\n",
    "conf_matrix_threshold = confusion_matrix(y_test, y_pred_threshold)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy Score (Threshold Adjusted Model):\", accuracy_threshold)\n",
    "print(\"\\nClassification Report (Threshold Adjusted Model):\\n\", class_report_threshold)\n",
    "print(\"\\nConfusion Matrix (Threshold Adjusted Model):\\n\", conf_matrix_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eef4ff-0172-4185-8330-d3f53ea1d466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
